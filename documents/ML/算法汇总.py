__file__ = "Machine Learning"

"""学习树
1、KNN
类别：二分类/多分类
说明：不关联特征之间的联系，以某种特征出现的频率，来划分前K标签进行分类
原理：{∑[(x(i) - x)**2 + (y(i) - y)**2 + (z(i) - z)**2 + ...]} ** 0.5

2、DTree
类别：多分类
说明：一种类权重分配算法。基于信息熵的混乱程度来决定某个特征的权重
原理：entropy = -∑[p*log(p, 2)]

3、NaiveBayes
类别：二分类/多分类
说明：基于独立假设，各特征之间无关联。在给定目标向量的前提下，计算该向量属于各个类别标签的概率，选择属于某概率最大的类别作为最终分类
原理：p(c|x) = p(c)*p(x|c)/p(x), p(x|c) = p(xc)/p(c)
    原理说明：在给定目标目标向量，求向量分类 = 各个标签的概率*在该标签的概率中，出现此目标向量的概率。底部的p(x)可以不做考虑，都有
    p(c)：各个标签发生的概率
    p(x)：目标向量，这里仅仅是一个统计作用，里面无概率成分。词集则仅统计1次，词带则统计多次。某个特征出现的频度，在乘以特征出现的概率，这样感觉可以接受多了
    p(x|c)：在某个标签c的前提下，目标向量发生的概率。在实际的计算过程中就是把目标向量与标签概率相乘。连对数都不需要取了
    p(c|x)：在给定目标向量的前提下，该向量来自c的概率

4、LogisticRegression/GradientDescent
类别：二分类
说明：梯度下降算法
原理：Cost'相当于斜率，修正W用此方法，往斜率方向步进，得到修正值
    Cost = -{∑[-y*log(h(x)) + (1-y)*log(1-h(x))]} / m
    Cost' = ∑[x(h(x)-y)] / m  

5、SVM/MVO

6、NeuralNetwork/感知器/神经网络/深度学习
感知器
h(x) = f(∑[WX])
W := W + learningRate*(y-h(x))*X

"""  # todo 目前新闻分类可以采用 KNN和NaiveBayes，但是NaiveBayes对数据训练有一定算法要求





"""新闻分类计划：
降低分类标签密度，初步优化各类模型

模型一：基于KNN模型，不关联词句之间的内在联系，以某种频度作为参考标准进行分类

模型二：基于NaiveBayes，同上，大幅优化计算过程，但模型训练需要一定优化

模型三：集成学习，综合模型一/二

模型四：基于NeuralNetwork
"""
